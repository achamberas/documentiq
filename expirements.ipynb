{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vertexai\n",
      "  Downloading vertexai-1.60.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-aiplatform==1.60.0 (from google-cloud-aiplatform[all]==1.60.0->vertexai)\n",
      "  Downloading google_cloud_aiplatform-1.60.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (2.19.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (2.27.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (21.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (3.24.0)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai)\n",
      "  Downloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai)\n",
      "  Downloading shapely-2.0.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: pydantic<3 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (1.10.12)\n",
      "Collecting docstring-parser<1 (from google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[33mWARNING: google-cloud-aiplatform 1.60.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (1.59.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from packaging>=14.3->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from pydantic<3->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (4.9.0)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (1.26.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (0.4.8)\n",
      "Requirement already satisfied: six>=1.5 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (1.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anthonychamberas/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->google-cloud-aiplatform[all]==1.60.0->vertexai) (2022.12.7)\n",
      "Downloading vertexai-1.60.0-py3-none-any.whl (7.3 kB)\n",
      "Downloading google_cloud_aiplatform-1.60.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.9/341.9 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.5-cp39-cp39-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely, docstring-parser, google-cloud-resource-manager, google-cloud-aiplatform, vertexai\n",
      "Successfully installed docstring-parser-0.16 google-cloud-aiplatform-1.60.0 google-cloud-resource-manager-1.12.5 shapely-2.0.5 vertexai-1.60.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU pypdf langchain langchain_community langchain_experimental langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create link to external models in BigQuery\n",
    "\n",
    "Based off of this article\n",
    "\n",
    "https://cloud.google.com/blog/products/data-analytics/how-to-use-rag-in-bigquery-to-bolster-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f8af97e17f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import google.auth\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# authenticate to Google Cloud\n",
    "\n",
    "GOOGLE_PROJECT = 'gristmill5'\n",
    "credentials = service_account.Credentials.from_service_account_file(\"creds/gristmill5-e521e2f08f35.json\")\n",
    "client = bigquery.Client(GOOGLE_PROJECT, credentials)\n",
    "\n",
    "# create link to embedding model\n",
    "\n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE MODEL `gristmill5.rag_test.gecko_embedding_model`\n",
    "REMOTE WITH CONNECTION `projects/gristmill5/locations/us/connections/vertex_ai`\n",
    "OPTIONS (ENDPOINT = 'textembedding-gecko');\n",
    "\"\"\"\n",
    "\n",
    "client.query(sql, project=GOOGLE_PROJECT).result()\n",
    "\n",
    "# create link to LLM\n",
    "\n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE MODEL `gristmill5.rag_test.gemini_llm_model`\n",
    "REMOTE WITH CONNECTION `projects/gristmill5/locations/us/connections/vertex_ai`\n",
    "OPTIONS (ENDPOINT = 'gemini-1.0-pro');\n",
    "\"\"\"\n",
    "\n",
    "client.query(sql, project=GOOGLE_PROJECT).result()\n",
    "\n",
    "# create table function that accepts a user query, finds similar chunks, and passes those chunks to the LLM\n",
    "\n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE TABLE FUNCTION rag_test.rag_query(querys STRING, route_type STRING, words INT64, doc_source ARRAY <STRING>, selected_distance FLOAT64) AS (\n",
    "with q_embeddings as (\n",
    "  SELECT\n",
    "    text_embedding,\n",
    "    content\n",
    "  FROM\n",
    "    ML.GENERATE_TEXT_EMBEDDING(\n",
    "      MODEL `rag_test.gecko_embedding_model`,\n",
    "      (\n",
    "        SELECT\n",
    "        CAST(querys AS STRING) AS content\n",
    "      )\n",
    "    )\n",
    "),\n",
    "\n",
    "a_embeddings as (\n",
    "  select * \n",
    "  from `rag_test.embeddings` \n",
    "  where source in UNNEST(doc_source)\n",
    "  and embedding_type = FORMAT('%s', route_type)\n",
    "  and FORMAT('%s', route_type) = 'summary'\n",
    "),\n",
    "\n",
    "v_search as (\n",
    "  SELECT *\n",
    "  FROM\n",
    "    VECTOR_SEARCH( \n",
    "      (\n",
    "        select * \n",
    "        from `rag_test.embeddings` \n",
    "        where source in UNNEST(doc_source)\n",
    "        -- and statistics is not null\n",
    "        and embedding_type = FORMAT('%s', route_type)\n",
    "        and FORMAT('%s', route_type) = 'details'\n",
    "      ),\n",
    "      'text_embedding',\n",
    "      (select * from q_embeddings where 1=1),\n",
    "      top_k => 5\n",
    "    )\n",
    "  WHERE distance < selected_distance\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM \n",
    "  ML.GENERATE_TEXT(\n",
    "    MODEL\n",
    "      `rag_test.gemini_llm_model`, \n",
    "      (\n",
    "        -- query for when an answer needs to contain specific details\n",
    "        SELECT\n",
    "          CONCAT(FORMAT('Answer this question in less than %d words:\\\\n\\\\n %s \\\\n\\\\n', words, querys), '\\\\n\\\\n by using these text chunks: \\\\n\\\\n', STRING_AGG(base.chunk, '\\\\n')) AS prompt, \n",
    "          -- CONCAT(FORMAT('Summarize these text chunks in less than %d words:\\\\n\\\\n', words), STRING_AGG(base.chunk, '\\\\n')) AS prompt, \n",
    "          ARRAY_AGG(\n",
    "            STRUCT(\n",
    "              base.id as id,\n",
    "              base.chunk as chunk,\n",
    "              -- base.statistics as statistics, \n",
    "              base.embedding_type,\n",
    "              -- base.ml_embed_text_status as status,\n",
    "              distance as distance\n",
    "            )\n",
    "          ) source_ids\n",
    "        FROM v_search\n",
    "\n",
    "        -- query for when answer needs to be a summary\n",
    "        UNION ALL SELECT \n",
    "          CONCAT(FORMAT('Summarize this text in less than %d words:\\\\n\\\\n', words), SUBSTRING(chunk, 1, 32760)) AS prompt, \n",
    "          [\n",
    "            STRUCT(\n",
    "              id,\n",
    "              chunk,\n",
    "              -- statistics, \n",
    "              embedding_type,\n",
    "              -- {} as status,\n",
    "              0.1 as distance\n",
    "            )\n",
    "          ] source_ids\n",
    "        FROM a_embeddings\n",
    "      ),\n",
    "      STRUCT(\n",
    "        0.4 AS temperature,\n",
    "        300 AS max_output_tokens,\n",
    "        0.5 AS top_p,\n",
    "        5 AS top_k,\n",
    "        TRUE AS flatten_json_output\n",
    "      )\n",
    "  )\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "client.query(sql, project=GOOGLE_PROJECT).result()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask Hacker News - 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f7d88bcff10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "INSERT INTO TABLE `rag_test.embeddings` as\n",
    "SELECT 'Ask HN' as source, *\n",
    "FROM ML.GENERATE_TEXT_EMBEDDING(\n",
    "  MODEL `rag_test.gecko_embedding_model`, (\n",
    "    SELECT cast(id AS STRING) id, concat(title, ': ', text) as content \n",
    "    FROM `bigquery-public-data.hacker_news.full` \n",
    "    where text is not null\n",
    "    and type = 'story'\n",
    "    and timestamp > '2024-01-01'\n",
    "    )\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "client.query(sql, project=GOOGLE_PROJECT).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "conn = sqlite3.connect('/Users/anthonychamberas/chat.db')\n",
    "# conn = sqlite3.connect('~/Library/Messages/chat.db')\n",
    "\n",
    "messages = pd.read_sql_query('''\n",
    "    select distinct h.id phone_number, chj.chat_id, m.ROWID message_id, m.text, m.attributedBody, HEX(m.attributedBody) hex_message, m.date, m.handle_id, datetime(m.date/1000000000 + strftime(\"%s\", \"2001-01-01\") ,\"unixepoch\",\"localtime\") as date_utc \n",
    "    from chat_handle_join chj \n",
    "    inner join chat_message_join cmj \n",
    "        on chj.chat_id = cmj.chat_id \n",
    "        -- and chj.handle_id in (7,8,9)\n",
    "    inner join message m \n",
    "        on cmj.message_id = m.ROWID \n",
    "    inner join handle h \n",
    "        on chj.handle_id = h.ROWID \n",
    "''', conn)\n",
    "\n",
    "mapping =  dict.fromkeys(range(32))\n",
    "\n",
    "messages['hex_message'] = messages['hex_message'].apply(lambda x: bytes.fromhex(x))\n",
    "messages['decoded'] = messages['hex_message'].str.decode(\"utf-8\", \"ignore\")\n",
    "messages['cleaned'] = messages['decoded'].str.translate(mapping)\n",
    "messages['stripped'] = messages['cleaned'].str.extract(r'\\+(.*)iI')\n",
    "\n",
    "messages['reps'] = messages['stripped'].str.extract(r'(\\dx\\d*)')\n",
    "messages['dots'] = messages['stripped'].str.extract(r'[….|…|..|…|..\\s|.. ](\\d*)')\n",
    "messages['comma'] = messages['stripped'].str.extract(r'(\\d*)[,]')\n",
    "\n",
    "#messages[['date_utc', 'chat_id', 'handle_id','stripped', 'reps', 'dots']].to_csv('cleaned.csv')\n",
    "messages[['date_utc', 'phone_number', 'chat_id', 'handle_id','stripped', 'reps', 'dots']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import streamlist as st\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = st.secrets[\"OPENAI_API_KEY\"]\n",
    "\n",
    "embed = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "chunk = ['embed this sentence.', 'search for this sentence']\n",
    "df = pd.DataFrame(chunk, columns=['chunk'])\n",
    "\n",
    "vectors = embed.embed_documents(df['chunk'])\n",
    "df['vectors'] = pd.Series(vectors).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "GOOGLE_PROJECT = 'gristmill5'\n",
    "credentials = service_account.Credentials.from_service_account_file(\"creds/gristmill5-e521e2f08f35.json\")\n",
    "client = bigquery.Client(GOOGLE_PROJECT, credentials)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(autodetect=True)\n",
    "#table_id = bigquery.Table('table') \n",
    "#table_id = client.create_table(table, exists_ok=True)\n",
    "\n",
    "job = client.load_table_from_dataframe(df,\"gristmill5.rag_test.table_id\",job_config=job_config).result()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>page</th>\n",
       "      <th>chunk</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tableau Zen - Visual Analytics Maturity Assess...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why does it matter to me?</td>\n",
       "      <td>0.280168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tableau Zen - Visual Analytics Maturity Assess...</td>\n",
       "      <td>0</td>\n",
       "      <td>How does it work?</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  page  \\\n",
       "8  Tableau Zen - Visual Analytics Maturity Assess...     0   \n",
       "4  Tableau Zen - Visual Analytics Maturity Assess...     0   \n",
       "\n",
       "                       chunk  similarity  \n",
       "8  Why does it matter to me?    0.280168  \n",
       "4          How does it work?    0.999999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.connectors import *\n",
    "\n",
    "sql = f\"\"\"\n",
    "    select * \n",
    "    from `rag_test.embeddings` \n",
    "    where source in UNNEST(['Tableau Zen - Visual Analytics Maturity Assessment.docx'])\n",
    "\"\"\"\n",
    "\n",
    "data = bq_conn(sql)\n",
    "\n",
    "query = 'How does it work?'\n",
    "query = query.replace(\"'\", \"\\\\'\")\n",
    "embed = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector = embed.embed_documents([query])\n",
    "\n",
    "# Calculate cosine similarities between the query vector and the dataset\n",
    "vectors = np.array(data['vectors'].to_list())\n",
    "# similarities = cosine_similarity(vectors, vector)\n",
    "\n",
    "# similarity_array = [s[0] for s in similarities]\n",
    "# similarity_df = pd.DataFrame(similarity_array, columns=['similarity'])\n",
    "similarities = pd.DataFrame([s[0] for s in cosine_similarity(vectors, vector)], columns=['similarity'])\n",
    "df = pd.concat([data, similarities], axis=1)\n",
    "\n",
    "n = 2\n",
    "# top_n_idx = np.argsort(similarity_array)[-n:]\n",
    "top_n_idx = np.argsort(df['similarity'])[-n:]\n",
    "references = df[['source', 'page', 'chunk', 'similarity']].iloc[top_n_idx]\n",
    "\n",
    "display(references)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
